{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # PyTorch Library\n",
    "import numpy # NumPy\n",
    "from sklearn.datasets import make_blobs # 사이킷런 라이브러리 / 데이터 생성용\n",
    "import matplotlib.pyplot as plt # 데이터 시각화 용도 라이브러리\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_dim = 2\n",
    "x_train, y_train = make_blobs(n_samples = 80,\n",
    "                             n_features = 2,\n",
    "                             centers=[[1,1], [-1,-1], [1, -1], [-1, 1]],\n",
    "                             shuffle=True,\n",
    "                             cluster_std=0.3)\n",
    "x_test, y_test = make_blobs(n_samples = 20,\n",
    "                             n_features = 2,\n",
    "                             centers=[[1,1], [-1,-1], [1, -1], [-1, 1]],\n",
    "                             shuffle=True,\n",
    "                             cluster_std=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XOR 문제로 치환하기 위해 (1,1), (-1,-1) => 0, (1,-1), (-1,1) => 1로 레이블을 바꾼다.\n",
    "def label_map(y_, from_, to_):\n",
    "    y = numpy.copy(y_)\n",
    "    for f in from_:\n",
    "        y[y_ == f] = to_\n",
    "    return y\n",
    "\n",
    "y_train = label_map(y_train, [0,1], 0)\n",
    "y_train = label_map(y_train, [2,3], 1)\n",
    "y_test = label_map(y_test, [0,1], 0)\n",
    "y_test = label_map(y_test, [2,3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 데이터 시각화 함수\n",
    "def vis_data(x, y = None, c='r'):\n",
    "    for x_, y_ in zip(x,y):\n",
    "        plt.plot(x_[0], x_[1], c+'o' if y_ == 0 else c+'+')\n",
    "        \n",
    "plt.figure()\n",
    "vis_data(x_train, y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 0., 0., 1., 1., 0., 0., 1.,\n",
       "        0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 1., 1., 1., 1., 0., 1., 0.,\n",
       "        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 1., 0., 0., 1., 0., 0.,\n",
       "        1., 0., 0., 0., 0., 1., 1., 0., 0., 1., 1., 0., 1., 1., 0., 1., 0., 1.,\n",
       "        1., 1., 1., 0., 0., 0., 1., 1.])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Numpy 배열을 pytorch의 Tensor로 변환한다.\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "x_test = torch.FloatTensor(x_test)\n",
    "y_train = torch.FloatTensor(y_train)\n",
    "y_test = torch.FloatTensor(y_test)\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- net의 모델 모형을 출력한다.\n",
      "Net(\n",
      "  (fc1): Linear(in_features=2, out_features=5, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (fc2): Linear(in_features=5, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n",
      "----\n",
      "fc1: tensor([[ 0.6926,  0.1023, -0.0940,  0.8105,  0.4915],\n",
      "        [ 0.8480, -0.0397, -0.1183,  0.8643,  0.4215],\n",
      "        [-0.4636,  1.0518, -0.0065,  0.3952,  0.9094],\n",
      "        [-0.8364, -0.0581, -1.2075,  0.0590, -0.3144],\n",
      "        [-0.1433, -0.9971, -1.5811,  0.2550, -0.9198],\n",
      "        [ 0.7930,  0.2056,  0.0596,  0.8731,  0.6334],\n",
      "        [-0.6882, -0.2136, -1.2482,  0.1073, -0.4005],\n",
      "        [ 0.3003, -0.8653, -1.1841,  0.4852, -0.6042],\n",
      "        [ 1.0841, -0.1510, -0.0646,  0.9608,  0.4153],\n",
      "        [ 0.8343,  0.2381,  0.1141,  0.8974,  0.6821],\n",
      "        [-0.3564,  0.7851, -0.1697,  0.4082,  0.6993],\n",
      "        [-0.3211,  0.9501, -0.0040,  0.4486,  0.8727],\n",
      "        [ 0.0338, -1.0086, -1.4782,  0.3378, -0.8553],\n",
      "        [-0.0524,  1.4416,  0.5939,  0.6469,  1.4588],\n",
      "        [ 0.0369, -0.8406, -1.3304,  0.3633, -0.6928],\n",
      "        [-1.1838,  0.0845, -1.3051, -0.0862, -0.3257],\n",
      "        [-0.8787, -0.2256, -1.3800,  0.0148, -0.4932],\n",
      "        [-1.2141,  0.0398, -1.3632, -0.1070, -0.3815],\n",
      "        [-0.1659,  1.5646,  0.6284,  0.6104,  1.5284],\n",
      "        [ 0.1746, -1.0294, -1.4066,  0.4019, -0.8153]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "relu: tensor([[0.6926, 0.1023, 0.0000, 0.8105, 0.4915],\n",
      "        [0.8480, 0.0000, 0.0000, 0.8643, 0.4215],\n",
      "        [0.0000, 1.0518, 0.0000, 0.3952, 0.9094],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0590, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.2550, 0.0000],\n",
      "        [0.7930, 0.2056, 0.0596, 0.8731, 0.6334],\n",
      "        [0.0000, 0.0000, 0.0000, 0.1073, 0.0000],\n",
      "        [0.3003, 0.0000, 0.0000, 0.4852, 0.0000],\n",
      "        [1.0841, 0.0000, 0.0000, 0.9608, 0.4153],\n",
      "        [0.8343, 0.2381, 0.1141, 0.8974, 0.6821],\n",
      "        [0.0000, 0.7851, 0.0000, 0.4082, 0.6993],\n",
      "        [0.0000, 0.9501, 0.0000, 0.4486, 0.8727],\n",
      "        [0.0338, 0.0000, 0.0000, 0.3378, 0.0000],\n",
      "        [0.0000, 1.4416, 0.5939, 0.6469, 1.4588],\n",
      "        [0.0369, 0.0000, 0.0000, 0.3633, 0.0000],\n",
      "        [0.0000, 0.0845, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0148, 0.0000],\n",
      "        [0.0000, 0.0398, 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 1.5646, 0.6284, 0.6104, 1.5284],\n",
      "        [0.1746, 0.0000, 0.0000, 0.4019, 0.0000]], grad_fn=<ReluBackward0>)\n",
      "fc2: tensor([[-0.1446],\n",
      "        [-0.0674],\n",
      "        [-0.7535],\n",
      "        [-0.2135],\n",
      "        [-0.1772],\n",
      "        [-0.2110],\n",
      "        [-0.2045],\n",
      "        [-0.1123],\n",
      "        [-0.0311],\n",
      "        [-0.2417],\n",
      "        [-0.6016],\n",
      "        [-0.6934],\n",
      "        [-0.1593],\n",
      "        [-1.1431],\n",
      "        [-0.1544],\n",
      "        [-0.2613],\n",
      "        [-0.2216],\n",
      "        [-0.2418],\n",
      "        [-1.2250],\n",
      "        [-0.1370]], grad_fn=<AddmmBackward>)\n",
      "sigmoid: tensor([[0.4639],\n",
      "        [0.4831],\n",
      "        [0.3201],\n",
      "        [0.4468],\n",
      "        [0.4558],\n",
      "        [0.4474],\n",
      "        [0.4491],\n",
      "        [0.4720],\n",
      "        [0.4922],\n",
      "        [0.4399],\n",
      "        [0.3540],\n",
      "        [0.3333],\n",
      "        [0.4602],\n",
      "        [0.2418],\n",
      "        [0.4615],\n",
      "        [0.4350],\n",
      "        [0.4448],\n",
      "        [0.4399],\n",
      "        [0.2271],\n",
      "        [0.4658]], grad_fn=<SigmoidBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.4639],\n",
       "        [0.4831],\n",
       "        [0.3201],\n",
       "        [0.4468],\n",
       "        [0.4558],\n",
       "        [0.4474],\n",
       "        [0.4491],\n",
       "        [0.4720],\n",
       "        [0.4922],\n",
       "        [0.4399],\n",
       "        [0.3540],\n",
       "        [0.3333],\n",
       "        [0.4602],\n",
       "        [0.2418],\n",
       "        [0.4615],\n",
       "        [0.4350],\n",
       "        [0.4448],\n",
       "        [0.4399],\n",
       "        [0.2271],\n",
       "        [0.4658]], grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Module class 상송\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.hidden_Size = hidden_size\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(input_size, hidden_size)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        relu = self.relu(fc1)\n",
    "        fc2 = self.fc2(relu)\n",
    "        output = self.sigmoid(fc2)\n",
    "        return output\n",
    "    \n",
    "    def _debug(self, x):\n",
    "        fc1 = self.fc1(x)\n",
    "        print(\"fc1:\", fc1)\n",
    "        \n",
    "        relu = self.relu(fc1)\n",
    "        print(\"relu:\", relu)\n",
    "        \n",
    "        fc2 = self.fc2(relu)\n",
    "        print(\"fc2:\", fc2)\n",
    "        \n",
    "        output = self.sigmoid(fc2)\n",
    "        print(\"sigmoid:\", output)\n",
    "        return output\n",
    "    \n",
    "net = Net(2, 5)\n",
    "print(\"---- net의 모델 모형을 출력한다.\")\n",
    "print(net)\n",
    "print(\"----\")\n",
    "net._debug(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 생성\n",
    "model = Net(2,5)\n",
    "\n",
    "# 학습율\n",
    "lr = 0.03\n",
    "\n",
    "# Binary Cross Entropy\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Epochs\n",
    "epochs = 2000\n",
    "\n",
    "# Stochastic Gradient Descent\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss before training 0.7115614414215088\n"
     ]
    }
   ],
   "source": [
    "# 모델을 학습하기 전 loss를 출력한다.\n",
    "# tensor.item() : 텐서의 값을 스칼라 값으로 출력한다. 여러 차원의 데이터인 경우엔 에러가 나온다.\n",
    "# 즉, 텐서의 차원이 1x1인 경우에만 사용할 수 있음\n",
    "model.eval()\n",
    "test_loss_before = criterion(model(x_test).view(-1), y_test)\n",
    "print(\"test_loss before training\", test_loss_before.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch at: 0, train loss: 0.005957100074738264\n",
      "epoch at: 100, train loss: 0.00581338070333004\n",
      "epoch at: 200, train loss: 0.005675789900124073\n",
      "epoch at: 300, train loss: 0.005543788429349661\n",
      "epoch at: 400, train loss: 0.005417115055024624\n",
      "epoch at: 500, train loss: 0.005295421462506056\n",
      "epoch at: 600, train loss: 0.005178480409085751\n",
      "epoch at: 700, train loss: 0.005065985955297947\n",
      "epoch at: 800, train loss: 0.004957740195095539\n",
      "epoch at: 900, train loss: 0.004853499121963978\n",
      "epoch at: 1000, train loss: 0.004753074608743191\n",
      "epoch at: 1100, train loss: 0.004656275734305382\n",
      "epoch at: 1200, train loss: 0.004562884569168091\n",
      "epoch at: 1300, train loss: 0.004472752101719379\n",
      "epoch at: 1400, train loss: 0.0043857344426214695\n",
      "epoch at: 1500, train loss: 0.004301665350794792\n",
      "epoch at: 1600, train loss: 0.004220394883304834\n",
      "epoch at: 1700, train loss: 0.004141796380281448\n",
      "epoch at: 1800, train loss: 0.0040657734498381615\n",
      "epoch at: 1900, train loss: 0.0039921910502016544\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    output = model(x_train)\n",
    "    loss = criterion(output.view(-1), y_train)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if epoch % 100 == 0 :\n",
    "        print(\"epoch at: {}, train loss: {}\".format(epoch, loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss after training 0.003266087966039777\n"
     ]
    }
   ],
   "source": [
    "# 학습 후의 가중치를 출력한다.\n",
    "test_loss_before = criterion(model(x_test).view(-1), y_test)\n",
    "print(\"test_loss after training\", test_loss_before.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_dict: OrderedDict([('fc1.weight', tensor([[-1.7294,  2.1685],\n",
      "        [-2.3416, -1.1150],\n",
      "        [ 1.6662, -0.9213],\n",
      "        [ 1.2619,  1.3879],\n",
      "        [ 1.7680,  1.8662]])), ('fc1.bias', tensor([-0.1526, -0.0158,  0.7883, -0.0984, -0.2078])), ('fc2.weight', tensor([[ 2.6387, -2.5046,  2.0151, -1.6347, -2.4659]])), ('fc2.bias', tensor([1.1443]))])\n"
     ]
    }
   ],
   "source": [
    "# 학습 결과를 파일로 저장한다.\n",
    "torch.save(model.state_dict(), './simple_ann_model.pt')\n",
    "print('state_dict: {}'.format(model.state_dict()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-1,1) =  0.9996472597122192\n",
      "(1,-1) =  0.9996463060379028\n",
      "(1,1) =  0.00048533553490415215\n",
      "(0,0) =  0.0006193481967784464\n"
     ]
    }
   ],
   "source": [
    "# 저장한 학습 결과를 가져온다.\n",
    "new_model = Net(2,5)\n",
    "new_model.load_state_dict(torch.load('./simple_ann_model.pt'))\n",
    "\n",
    "print(\"(-1,1) = \", new_model(torch.Tensor([-1, 1])).item())\n",
    "print(\"(1,-1) = \", new_model(torch.Tensor([1, -1])).item())\n",
    "print(\"(1,1) = \", new_model(torch.Tensor([1, 1])).item())\n",
    "print(\"(-1,-1) = \", new_model(torch.Tensor([-1, -1])).item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
