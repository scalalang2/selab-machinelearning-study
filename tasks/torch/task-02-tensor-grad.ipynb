{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch AUTOGRAD\n",
    "pytorch는 AUTOGRAD 라고 해서 딥러닝의 핵심인 미분 연산을 자동으로 해주는 매커니즘이 존재한다. Tensor를 생성할 때 인자값으로 `requires_grad=True`를 설정해주면 각 연산이 실행될 때 마다 자동으로 미분 연산 과정을 트래킹 한다. 아래 예제에서는 `Tensor(x)`에 AUTOGRAD를 설정해주었고 `x+2`를 수행하였다. 그 결과 y를 출력해보면 그 미분 연산을 뜻하는 Backward Object `grad_fn`인자에 추가 된 것을 알 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n",
      "<AddBackward0 object at 0x118ef7890>\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)\n",
    "\n",
    "y = x + 2\n",
    "print(y)\n",
    "print(y.grad_fn)\n",
    "\n",
    "z = y * y * 3\n",
    "out = z.mean()\n",
    "print(z, out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`requires_grad` 옵션은 기본적으로 `False`값이다. 중간에 **requires_grad_** 를 이용해서 AUTOGRAD 모드를 활성화 할 수 있다. 다만 그 이전에 수행된 결과들은 미분 과정에 포함되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n",
      "<SumBackward0 object at 0x118f1c710>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "a = ((a*3)/(a-1))\n",
    "print(a.requires_grad)\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a * a).sum()\n",
    "print(b.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "최종 결과인 out의 backward()를 수행한다.\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(\"최종 결과인 out의 backward()를 수행한다.\")\n",
    "\n",
    "out.backward()\n",
    "print(x.grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
